{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #em __init__ definimos cada uma das camadas\n",
    "    def __init__(self, activate_dropout=False, weightDecay=0):\n",
    "        super(Net, self).__init__()\n",
    "        #fc1 corresponde à camada de entrada e terá 20 neurônios\n",
    "        self.fc1 = nn.Linear(10, 20)\n",
    "        #a função de ativação utilizada para cada neurônio é tanh\n",
    "        self.rl1 = nn.Tanh()\n",
    "        # sigmoid ou relu\n",
    "        #fc2 corresponde à camada oculta, também tendo 20 neurônios\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.rl2 = nn.Tanh()\n",
    "        #já fc3 corresponde à cama de saída, com apenas 3 neurônios, visto que lidamos com\n",
    "        #3 classes na classificação\n",
    "        self.fc3 = nn.Linear(20, 3)\n",
    "        #a função de saída será softmax, recomendado para casos de classificação com múltiplas\n",
    "        #classes\n",
    "        # sigmoid\n",
    "        self.smout = nn.Softmax(dim=1)      \n",
    "        \n",
    "        #a função de loss utilizada é L1 (MAE, ou erro absoluto médio)\n",
    "        self.criterion = nn.L1Loss()\n",
    "        #o otimizador selecionado foi Adam\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        self.activate_dropout=activate_dropout\n",
    "    def forward(self, x):\n",
    "        #o PyTorch requer que o forward propagation seja declarado para cada camada\n",
    "        x = self.fc1(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.do1(x)\n",
    "        x = self.rl1(x)\n",
    "        x = self.fc2(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.do2(x)\n",
    "        x = self.rl2(x)\n",
    "        x = self.fc3(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.do3(x)\n",
    "        x = self.smout(x)\n",
    "        return x\n",
    "    def loss(self, loss_set):\n",
    "        #a função de loss é definida\n",
    "        inputs, labels = unstitch(loss_set)\n",
    "        inputs = Variable(torch.FloatTensor(inputs))\n",
    "        labels = Variable(torch.FloatTensor(labels))\n",
    "        result = self(inputs)\n",
    "        loss = self.criterion(result, torch.max(labels, 1)[1])\n",
    "\n",
    "        return float(loss.item())\n",
    "    def train(self, numEpochs, train):\n",
    "        #função que realiza o treino da rede\n",
    "        #o treino inicia com a separação dos parâmetros e das labels\n",
    "        inputs, labels = unstitch(train)\n",
    "        \n",
    "        inputs = Variable(torch.FloatTensor(inputs))\n",
    "        labels = Variable(torch.FloatTensor(labels))\n",
    "\n",
    "        #em seguida, para cada época é realizado o forward propagation, e então o otimizador\n",
    "        #efetua o back propagation atualizando os pesos de cada neurônio\n",
    "        #os resultados de cada época são armazenados para exibição no TensorBoard\n",
    "        for epoch in range(numEpochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self(inputs)\n",
    "            self.loss = self.criterion(outputs, labels)\n",
    "            self.loss.backward()    \n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.store_results(epoch, train)\n",
    "            self.print_final_train_acc(epoch, train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a063a9d6d4095dba70f7d4a438ef288e94ffec589b0525f5b20de998ec61033a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
